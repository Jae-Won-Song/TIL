# 머신러닝

- 명시적으로 데이터를 프로그래밍 해 학습시키는 것

- 데이터를 입힘으로서 성능이 향상되는것

---

## 머신러닝의 분류

1. `SUPERVISED LEARNING `(지도학습)
   - 데이터에 정답이 있는 경우 사용
     1. CLASSFICATION - (분류모델)
     2. REGRESSION - (회귀모델)
2. `UNSUPERVISED LEARNING` (비지도학습)
   - 데이터에 정답이 없는경우 사용
     1. DIMENSIONALLY REDUCTION - (차원축소)
     2. CLUSTERING - (군집분석)
3. `REINFORCEMENT LEARNING`

---

### 지도학습과 비지도학습의 차이

- 지도학습은 정답을 부여 후 정답에 따라 분류
- 비지도학습은 분석 후 스스로 분류

---

## SUPERVISED learning

- Input data에 대한 정답을 예측하기 위해 학습
  - (`Function approximator`)
- 데이터에 정답(Label, Target)존재
- Output 형태에 따라 회귀분석, 분류 분석으로 나눔
  - 회귀분석 (Regression) : Output이 실수 영역 전체에서 나타남
  - 분류분석 (Classfication) : Output이 class에 해당하는 불연속값으로 나타남

---

## Unsupervised learning

- Input data 속에 숨어있는 규칙성을 찾기 위해 학습
  - `(shorter Description)`
- 데이터에 정답(Label, Target) 존재하지 않음
  - 군집분석 (Clustering Algorithm)
  - 차원축소 (Dimensionality reducton or Compression)

```
Column = Attribute = Dimension = Feature
```

---

## Reinforcement

- Trial & Error 등을 통해 학습
  - `(Sequential decision making)`

---

## 학습?

- 실제정답과 예측결과 사이의 오차를 줄여나가는 최적화 과정

Model's Capacity => 함수의 차수에 따라 올라감

- Capacity의 극대화 => Overfitting 발생 => Generalization error 증가 => 새로운 데이터에 잘 대응하지 못함

### 새로운 데이터들에 대해서도 좋은 결과를 내게하려면?

1. Cross Validation (교차검증)

   - 데이터를 3개의 그룹으로 나눈다

   1. 60%의 Traning data로 모델 학습시킨다
   2. 20%의 Validation data로 모델(or Hype parameter)을 최적화/선택(Tune)한다
   3. 20%의 Test data로 모델을 평가(Test only, no more tune)한다

2. (Stratified) K-Fold cross validation - (후보 모델 간 비교 및 선택을 위한 알고리즘)
   - K => 숫자를 직접 정함
   - CV
     - `cross validation`
     - compution vision
     - curriculum vision

---

<!-- 23.03.13 -->

## 선형 회귀

- **종속 변수 y**와 **한 개 이상의 독립 변수(설명 변수)x**사이의 선형 상관 관계를 모델링하는 회귀분석 기법
  - `정답이 있는 데이터의 추세`를 잘 설명하는 `선형 함수`를 찾아` x에 대한  y`를 예측
  - 1개의 독립변수가 1개의 종속변수에 영향 -> 단순 회귀분석
  - 2개 이상의 독립변수가 1개의 종속변수에 영향 -> 다중 회귀분석

== 가장 적합한 세타를 찾는게 목표

### cost Function (비용함수)

- 예측값의 실제 값의 `차이`를 기반으로 모델의 성능을 예측하기 위한 함수

1. 평균제곱오차함수(MSE function)

   - 회귀분석에서 활용하는 cost function중 가장 대표적
   - 오차를 제곱한 후 평균값을 구해 0에 수렴 할 수록 신뢰도 올라감

     - J세타 = 비용함수

2. Gradient Descent Algorithm(경사 하강법)
   - **Gradient** => 모든 변수(세타)의 편미분을 벡터로 정리한 것(=함수의 기울기, 경사)
   - 편미분 => 변수가 2개이상이 함수를 미분할 때 미분 대상의 변수 외에 나머지 변수를 상수처럼 고정시켜 미분

- Learning Rate (학습률) == 보폭(stepsize)
  - 얼마나 큰 보폭으로 움직일지를 결정해주는 값

---

    1. 변수 세타의 초기값을 설정
    2. 현재 변수값에  대응되는 Cost function 경사도 계산(미분)
    3. 변수를 경사 방향(Gradient의 음의방향)으로 움직여 다음 변수 값으로 설정
    4. 1~3을 반복하며 Cost function이 최소가 되도록 하는 변수값으로 근접해 나간다
       - 전체 Cost 값이 변하지 않거나 매우 느리게 변할 때까지 접근

HPO -> 멀티값을 가장 적합한 값으로 찾아내는것

==> (`H`yper `P`arameter `O`ptimization)

---

# Logistic Regression (로지스틱 회귀)

### `성능지표로 Mean Squared Error가 아닌, 분류를 위한 Cost function인 Cross-entropy를 활용`

- `이진 분류 문제`를 해결하귀 위한 모델
  - `Sigmoid function` 을 이용하여 기본적으로 특정 Input data 가 양성 class 에 속할 확률을 계산
  - `Sigmoid function` 의 정확한 y값을 받아 양성일 확률을 예측하거나, 특정 cutoff를 넘는 경우 양성, 그 외에는 음성으로 예측가능

---

# Softmax Algorithm (소프트 맥스 알고리즘)

- 다중 클래스 분류 문제를 위한 알고리즘 (일종의 함수)
  - model 의 output에 해당하는 logit(score)을 각 클래스에 소속될 확률에 해당하는 값들의 벡터로 변환해준다.
  - Logistic regression를 변형/발전시킨 방법으로, binary class 문제를 벗어나 multiple class 문제로 일반화시켜 적용할 수 있다.

---

<!-- 23.03.14 -->

TPR(True Postive Rate)

- 진양성율(실제 참인 것 중 모델이 참이라고 예측한 비율)

```
TP/TP+FN
```

FPR(False Postive Rate)

- 위양성율(실제 거짓인 것 중 모델이 참이라고 예측한 비율)

```
FP/TN+FP
```

# ROC Curve

Receiver operating characteristic Curve

- 아래쪽 면적
  - AUC (Area Under the ROC Curve)
  - 면적이 넓을수록 신뢰도 상승

---

# SVM_1 (Supprot Vector Machine)

- Margin을 최대화하는 결정 경계(면)을 찾는 기법
- 패턴 인식을 위한 지도 학습 모델 분류 뿐만 아니라 회귀에도 사용 가능
- 딥러닝 이전에 뛰어난 성능으로 많은 주목을 받은 머신러닝 알고리즘

---

# SVM_2 (Soft-Margin SVM)

- 현실에서는 매우 `엄격하게 2개의 클래스로만 데이터를 분리하기 어려움`
  - 소수의 noise로 인해 결정경계를 찾지 못할 수도 있음

--> 서포트 벡터가 위치한 `Plus & Minus plane에 약간의 여유번슈(Slack Variable)을 두는 것`으로 해결

---

# SVM_3 (Kernel Support Vector Machines)

- 데이터가 선형적으로 분리되지 않을 경우
- 커널함수를 사용

--> Original data가 놓여있는 차원을 `비션헝 매핑을 통해 고차원 공간으로 변환`하는 것으로 해결

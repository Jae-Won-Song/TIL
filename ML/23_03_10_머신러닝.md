# 머신러닝

- 명시적으로 데이터를 프로그래밍 해 학습시키는 것

- 데이터를 입힘으로서 성능이 향상되는것

---

## 머신러닝의 분류

1. `SUPERVISED LEARNING `(지도학습)
   - 데이터에 정답이 있는 경우 사용
      1. CLASSFICATION - (분류모델)
      2. REGRESSION - (회귀모델)
2. `UNSUPERVISED LEARNING` (비지도학습)
   - 데이터에 정답이 없는경우 사용
      1. DIMENSIONALLY REDUCTION - (차원축소)
      2. CLUSTERING - (군집분석)
3. `REINFORCEMENT LEARNING`

---

### 지도학습과 비지도학습의 차이

- 지도학습은 정답을 부여 후 정답에 따라 분류
- 비지도학습은 분석 후 스스로 분류

---

## SUPERVISED learning

- Input data에 대한 정답을 예측하기 위해 학습
  - (`Function approximator`)
- 데이터에 정답(Label, Target)존재
- Output 형태에 따라 회귀분석, 분류 분석으로 나눔
  - 회귀분석 (Regression) : Output이 실수 영역 전체에서 나타남
  - 분류분석 (Classfication) : Output이 class에 해당하는 불연속값으로 나타남
  

---

## Unsupervised learning

- Input data 속에 숨어있는 규칙성을 찾기 위해 학습 
  - `(shorter Description)`
- 데이터에 정답(Label, Target) 존재하지 않음
  - 군집분석 (Clustering Algorithm)
  - 차원축소 (Dimensionality reducton or Compression)

```
Column = Attribute = Dimension = Feature
```

---

## Reinforcement
- Trial & Error 등을 통해 학습 
  - `(Sequential decision making)`

---

## 학습?

- 실제정답과 예측결과 사이의 오차를 줄여나가는 최적화 과정

Model's Capacity => 함수의 차수에 따라 올라감

- Capacity의 극대화 => Overfitting 발생 => Generalization error 증가 => 새로운 데이터에 잘 대응하지 못함

### 새로운 데이터들에 대해서도 좋은 결과를 내게하려면?

1. Cross Validation (교차검증)
    - 데이터를 3개의 그룹으로 나눈다
    1. 60%의 Traning data로 모델 학습시킨다
    2. 20%의 Validation data로 모델(or Hype parameter)을 최적화/선택(Tune)한다
    3. 20%의 Test data로 모델을 평가(Test only, no more tune)한다

2. (Stratified) K-Fold cross validation - (후보 모델 간 비교 및 선택을 위한 알고리즘)
    - K => 숫자를 직접 정함
    - CV 
      - `cross validation`
      - compution vision
      - curriculum vision
---
<!-- 23.03.13 -->

## 선형 회귀

- **종속 변수 y**와 **한 개 이상의 독립 변수(설명 변수)x**사이의 선형 상관 관계를 모델링하는 회귀분석 기법
  - `정답이 있는 데이터의 추세`를 잘 설명하는 `선형 함수`를 찾아` x에 대한  y`를 예측
  - 1개의 독립변수가 1개의 종속변수에 영향 -> 단순 회귀분석
  - 2개 이상의 독립변수가 1개의 종속변수에 영향 -> 다중 회귀분석

== 가장 적합한 세타를 찾는게 목표

### cost Function (비용함수)
- 예측값의 실제 값의 `차이`를 기반으로 모델의 성능을 예측하기 위한 함수

1. 평균제곱오차함수(MSE function)
   - 회귀분석에서 활용하는 cost function중 가장 대표적
   - 오차를 제곱한 후 평균값을 구해 0에 수렴 할 수록 신뢰도 올라감

      - J세타 = 비용함수

2. Gradient Descent Algorithm(경사 하강법)
   - **Gradient** => 모든 변수(세타)의 편미분을 벡터로 정리한 것(=함수의 기울기, 경사)
   - 편미분 => 변수가 2개이상이 함수를 미분할 때 미분 대상의 변수 외에  나머지 변수를 상수처럼 고정시켜 미분
  
  - Learning Rate (학습률) == 보폭(stepsize)
    - 얼마나 큰 보폭으로 움직일지를 결정해주는 값
  ---
    1. 변수 세타의 초기값을 설정
    2. 현재 변수값에  대응되는 Cost function 경사도 계산(미분)
    3. 변수를 경사 방향(Gradient의 음의방향)으로 움직여 다음 변수 값으로 설정
    4. 1~3을 반복하며 Cost function이 최소가 되도록 하는 변수값으로 근접해 나간다
       - 전체 Cost 값이 변하지 않거나 매우 느리게 변할 때까지 접근

HPO -> 멀티값을 가장 적합한 값으로 찾아내는것

==> (`H`yper `P`arameter `O`ptimization)


# 머신러닝

- 명시적으로 데이터를 프로그래밍 해 학습시키는 것

- 데이터를 입힘으로서 성능이 향상되는것

---

## 머신러닝의 분류

1. `SUPERVISED LEARNING `(지도학습)
   - 데이터에 정답이 있는 경우 사용
      1. CLASSFICATION - (분류모델)
      2. REGRESSION - (회귀모델)
2. `UNSUPERVISED LEARNING` (비지도학습)
   - 데이터에 정답이 없는경우 사용
      1. DIMENSIONALLY REDUCTION - (차원축소)
      2. CLUSTERING - (군집분석)
3. `REINFORCEMENT LEARNING`

---

### 지도학습과 비지도학습의 차이

- 지도학습은 정답을 부여 후 정답에 따라 분류
- 비지도학습은 분석 후 스스로 분류

---

## SUPERVISED learning

- Input data에 대한 정답을 예측하기 위해 학습
  - (`Function approximator`)
- 데이터에 정답(Label, Target)존재
- Output 형태에 따라 회귀분석, 분류 분석으로 나눔
  - 회귀분석 (Regression) : Output이 실수 영역 전체에서 나타남
  - 분류분석 (Classfication) : Output이 class에 해당하는 불연속값으로 나타남
  

---

## Unsupervised learning

- Input data 속에 숨어있는 규칙성을 찾기 위해 학습 
  - `(shorter Description)`
- 데이터에 정답(Label, Target) 존재하지 않음
  - 군집분석 (Clustering Algorithm)
  - 차원축소 (Dimensionality reducton or Compression)

```
Column = Attribute = Dimension = Feature
```

---

## Reinforcement
- Trial & Error 등을 통해 학습 
  - `(Sequential decision making)`

---

## 학습?

- 실제정답과 예측결과 사이의 오차를 줄여나가는 최적화 과정

Model's Capacity => 함수의 차수에 따라 올라감

- Capacity의 극대화 => Overfitting 발생 => Generalization error 증가 => 새로운 데이터에 잘 대응하지 못함

### 새로운 데이터들에 대해서도 좋은 결과를 내게하려면?

1. Cross Validation (교차검증)
    - 데이터를 3개의 그룹으로 나눈다
    1. 60%의 Traning data로 모델 학습시킨다
    2. 20%의 Validation data로 모델(or Hype parameter)을 최적화/선택(Tune)한다
    3. 20%의 Test data로 모델을 평가(Test only, no more tune)한다

2. (Stratified) K-Fold cross validation - (후보 모델 간 비교 및 선택을 위한 알고리즘)
    - K => 숫자를 직접 정함
    - CV 
      - `cross validation`
      - compution vision
      - curriculum vision